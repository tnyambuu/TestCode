{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231ef877",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import gc\n",
    "import tempfile\n",
    "import pdfplumber\n",
    "import camelot\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from typing import Dict, Any, Optional, Type, List\n",
    "from dateutil import parser\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "class XacBank25Parser():\n",
    "    \"\"\"\n",
    "    Parser for the TDB regular statement format.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        sources_dir: str = \"sources\",\n",
    "        results_dir: str = \"results\",\n",
    "        # model_class: Optional[Type[Model]] = None,\n",
    "        name_pattern: str = r'Дансны нэр :\\s*([^\\n]+)',\n",
    "        account_pattern: str = r'Дансны дугаар :\\s*(\\d+)\\s*',\n",
    "        account_type_pattern: str = r'Валют :\\s*([^\\n]+)',\n",
    "        table_start_pattern: str = r'Цаг Салбар',\n",
    "        table_end_pattern: str = r'Огноо Гүйлгээ хийсэн банк',\n",
    "    ):\n",
    "        # super().__init__(sources_dir, results_dir)\n",
    "        self.name_pattern = name_pattern\n",
    "        self.account_pattern = account_pattern\n",
    "        self.account_type_pattern = account_type_pattern\n",
    "        self.table_start_pattern = table_start_pattern\n",
    "        self.table_end_pattern = table_end_pattern\n",
    "        self.statement_parser = 'xacbank_25'\n",
    "\n",
    "    def extract_customer_details(self, text: str) -> Dict[str, str]:\n",
    "        \"\"\"Extract customer details from the text content.\"\"\"\n",
    "\n",
    "        details = {\n",
    "            'first_name': '',\n",
    "            'last_name': '',\n",
    "            'account_number': '',\n",
    "            'account_type': '',\n",
    "            'statement_parser': self.statement_parser\n",
    "        }\n",
    "\n",
    "        try:\n",
    "            # Extract customer name\n",
    "            name_match = re.search(self.name_pattern, text)\n",
    "            if name_match:\n",
    "                full_name = name_match.group(1).strip()\n",
    "                # Split the name into first and last name\n",
    "                name_parts = full_name.split()\n",
    "                if len(name_parts) >= 2:\n",
    "                    details['last_name'] = name_parts[0]\n",
    "                    details['first_name'] = name_parts[1]\n",
    "\n",
    "            # Extract account number\n",
    "            account_match = re.search(self.account_pattern, text)\n",
    "            if account_match:\n",
    "                details['account_number'] = account_match.group(1)\n",
    "\n",
    "            # Extract account type\n",
    "            account_type_match = re.search(self.account_type_pattern, text)\n",
    "            if account_type_match:\n",
    "                details['account_type'] = account_type_match.group(0).strip()\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error extracting customer details: {str(e)}\")\n",
    "\n",
    "        return details\n",
    "\n",
    "    def extract_statement_details(self, pdf_file: str, start_page: int = None, end_page: int = None) -> List[Dict[str, Any]]:\n",
    "        \"\"\"\n",
    "        Extract statement details from the text content.\n",
    "\n",
    "        Args:\n",
    "            pdf_file: Either a file path string or a file object\n",
    "            start_page (int, optional): Starting page number (1-indexed). If None, starts from page 1.\n",
    "            end_page (int, optional): Ending page number (1-indexed). If None, processes all pages.\n",
    "\n",
    "        Returns:\n",
    "            List[Dict[str, Any]]: List of parsed transactions\n",
    "        \"\"\"\n",
    "\n",
    "        try:\n",
    "            # Determine page range for Camelot\n",
    "            if start_page is not None and end_page is not None:\n",
    "                # Convert to Camelot's page format (comma-separated string)\n",
    "                page_range = ','.join(str(i) for i in range(start_page, end_page + 1))\n",
    "                print(f\"TDB Old processing pages: {page_range}\")\n",
    "            elif start_page is not None:\n",
    "                page_range = f\"{start_page}-end\"\n",
    "                print(f\"TDB Old processing pages: {page_range}\")\n",
    "            elif end_page is not None:\n",
    "                page_range = f\"1-{end_page}\"\n",
    "                print(f\"TDB Old processing pages: {page_range}\")\n",
    "            else:\n",
    "                page_range = 'all'\n",
    "                print(\"TDB Old processing all pages\")\n",
    "\n",
    "            # Handle both file paths and file objects\n",
    "            if hasattr(pdf_file, 'read'):\n",
    "                # If it's a file object, save it temporarily\n",
    "                with tempfile.NamedTemporaryFile(suffix='.pdf', delete=False) as temp_file:\n",
    "                    for chunk in pdf_file.chunks():\n",
    "                        temp_file.write(chunk)\n",
    "\n",
    "                    print(\"temp file\", temp_file.name)\n",
    "                    temp_file_path = temp_file.name\n",
    "\n",
    "                try:\n",
    "                    tables = camelot.read_pdf(temp_file_path, pages=page_range, flavor='stream')\n",
    "                except SystemExit as e:\n",
    "                    print(f\"Camelot SystemExit error: {e}. Falling back to empty result.\")\n",
    "                    tables = []\n",
    "                except Exception as e:\n",
    "                    print(f\"Camelot processing error: {e}. Falling back to empty result.\")\n",
    "                    tables = []\n",
    "                finally:\n",
    "                    # Clean up the temporary file\n",
    "                    if os.path.exists(temp_file_path):\n",
    "                        os.unlink(temp_file_path)\n",
    "            else:\n",
    "                # If it's a file path, use it directly\n",
    "                try:\n",
    "                    tables = camelot.read_pdf(pdf_file, pages=page_range, flavor='stream')\n",
    "                except SystemExit as e:\n",
    "                    print(f\"Camelot SystemExit error: {e}. Falling back to empty result.\")\n",
    "                    tables = []\n",
    "                except Exception as e:\n",
    "                    print(f\"Camelot processing error: {e}. Falling back to empty result.\")\n",
    "                    tables = []\n",
    "        except Exception as e:\n",
    "            print(f\"Error extracting tables from PDF: {str(e)}\")\n",
    "            return []\n",
    "\n",
    "        print(f\"Found {len(tables)} tables\")\n",
    "\n",
    "        clean_tran = []\n",
    "\n",
    "        for idx, table in enumerate(tables):\n",
    "            raw_data = table.data\n",
    "\n",
    "            for row_idx, row in enumerate(raw_data):\n",
    "                if \"Хэвлэсэн огноо :\" in row:\n",
    "                    print(\"row\")\n",
    "                # Skip header rows\n",
    "                if row_idx == 0:\n",
    "                    continue\n",
    "                elif row[2] == 'Эхний үлдэгдэл':\n",
    "                    continue\n",
    "                elif row[0] == 'Дансны төрөл :':\n",
    "                    continue\n",
    "                elif row[0] == 'Хугацаа :':\n",
    "                    continue\n",
    "                elif row[0] == 'Огноо':\n",
    "                    continue\n",
    "                elif any(val == 'Энэхүү дансны хуулга нь мэдээллийг орхигдуулсан болон алдаатай мэдээлэл агуулж байвал энэ талаар дансны хуулга авснаас хойш ажлын 10' for i, val in enumerate(row)):\n",
    "                    continue\n",
    "                elif any(val == 'өдөрт багтаан салбарын захирал, эсвэл нягтлан бодогчид бичгээр мэдэгдэнэ үү.' for i, val in enumerate(row)):\n",
    "                    continue\n",
    "                elif row[2] == 'Эцсийн үлдэгдэл :':\n",
    "                    continue\n",
    "                elif row[0] == 'Нийт':\n",
    "                    break\n",
    "\n",
    "                row = [str(val).strip() for val in row]\n",
    "\n",
    "                if len(row) == 7:\n",
    "                    row.pop(3) if row[4] else row.pop(4)\n",
    "\n",
    "                clean_tran.append(row)\n",
    "\n",
    "        print(\"Extracted clean data count: \", len(clean_tran))\n",
    "        group_counter = 0\n",
    "\n",
    "        for idx, row in enumerate(clean_tran):\n",
    "            if row[0] == '':\n",
    "                row.insert(0, group_counter)\n",
    "            else:\n",
    "                group_counter += 1\n",
    "                row.insert(0, group_counter)\n",
    "\n",
    "        for idx, row in enumerate(clean_tran):\n",
    "            try:\n",
    "                if row[1] == '':\n",
    "                    continue\n",
    "\n",
    "                next_idx = idx + 1\n",
    "\n",
    "                while (next_idx < len(clean_tran)):\n",
    "                    if clean_tran[next_idx][1] == '':\n",
    "                        next_idx += 1\n",
    "                    else:\n",
    "                        break\n",
    "\n",
    "                if next_idx < len(clean_tran) and next_idx != idx + 1 and clean_tran[next_idx - 1][2] != 'Used':\n",
    "                    clean_tran[next_idx - 1][0] = clean_tran[next_idx][0]\n",
    "                    clean_tran[next_idx + 1][0] = clean_tran[next_idx][0]\n",
    "                    clean_tran[next_idx - 1][2] = 'Used'\n",
    "                    clean_tran[next_idx + 1][2] = 'Used'\n",
    "            except Exception as e:\n",
    "                print(\"Grouping loop error:\", e)\n",
    "\n",
    "        group_rows = defaultdict(list)\n",
    "\n",
    "        for idx, row in enumerate(clean_tran):\n",
    "            group_rows[row[0]].append(row)\n",
    "\n",
    "\n",
    "        if not group_rows[0][0][1]:\n",
    "            group_rows[1] = group_rows[0] + group_rows[1]\n",
    "            group_rows.pop(0)\n",
    "\n",
    "        del clean_tran\n",
    "\n",
    "        group_rows_list = list(group_rows.items())\n",
    "        processed_list = []\n",
    "\n",
    "        for idx, row in enumerate(group_rows_list):\n",
    "            concat_desc = list()\n",
    "            concat_row = list()\n",
    "\n",
    "            if (idx == 0):\n",
    "                continue\n",
    "\n",
    "            for idx, value in enumerate(row[1]):\n",
    "                concat_desc.append(value[3])\n",
    "\n",
    "                if (value[1] != ''):\n",
    "                    concat_row = value\n",
    "\n",
    "            transaction = {\n",
    "                'type': 'income' if concat_row[4] and float(concat_row[4].replace(',', '')) > 0 else 'expense',\n",
    "                'date': None,\n",
    "                'income': float(concat_row[4].replace(',', '')) if concat_row[4] else None,\n",
    "                'expense': float(concat_row[5].replace(',', '')) if concat_row[5] else None,\n",
    "                'balance_end': float(concat_row[6].replace(',', '')) if concat_row[5] else 0,\n",
    "                'related_account': '',\n",
    "                'related_account_name': '',\n",
    "                'description': ' '.join(concat_desc)\n",
    "            }\n",
    "\n",
    "            processed_list.append(transaction)\n",
    "\n",
    "        del group_rows_list\n",
    "\n",
    "        return processed_list\n",
    "\n",
    "\n",
    "    def parse_pdf(self, pdf_path: Path, register_number: str, request=None, start_page: int = None, end_page: int = None, chunk_size: int = 10) -> str:\n",
    "        \"\"\"Parse a single PDF file and extract its text content.\"\"\"\n",
    "\n",
    "        result = {\n",
    "            'id': \"\",\n",
    "            'name': \"\", # full name\n",
    "            'account': \"\",\n",
    "            'created_transactions': 0\n",
    "        }\n",
    "\n",
    "        try:\n",
    "            with pdfplumber.open(pdf_path) as pdf:\n",
    "                # Get first page for customer details\n",
    "                first_page = pdf.pages[0]\n",
    "                first_page_text = first_page.extract_text()\n",
    "\n",
    "                # Extract and save customer details\n",
    "                customer_details = self.extract_customer_details(first_page_text)\n",
    "                # customer, account = self.save_customer_details(customer_details, register_number, request)\n",
    "                account = customer_details\n",
    "                customer = customer_details\n",
    "\n",
    "                if account:\n",
    "                    print(f\"Successfully saved customer details for account {account['account_number']}\")\n",
    "\n",
    "                    # Determine page range for processing\n",
    "                    total_pages = len(pdf.pages)\n",
    "                    start_idx = (start_page - 1) if start_page is not None else 0\n",
    "                    end_idx = end_page if end_page is not None else total_pages\n",
    "\n",
    "                    # Validate page range\n",
    "                    start_idx = max(0, start_idx)  # Ensure start is not negative\n",
    "                    end_idx = min(total_pages, end_idx)  # Ensure end doesn't exceed total pages\n",
    "\n",
    "                    if start_idx >= end_idx:\n",
    "                        print(f\"Invalid page range: start_page={start_page}, end_page={end_page}, total_pages={total_pages}\")\n",
    "                        return result\n",
    "\n",
    "                    print(f\"TDB Old processing pages {start_idx + 1} to {end_idx} of {total_pages} total pages in chunks of {chunk_size}\")\n",
    "\n",
    "                    # Process pages in chunks to prevent memory issues\n",
    "                    total_transactions = 0\n",
    "                    chunk_start = start_idx\n",
    "\n",
    "                    while chunk_start < end_idx:\n",
    "                        chunk_end = min(chunk_start + chunk_size, end_idx)\n",
    "                        print(f\"TDB Old processing chunk: pages {chunk_start + 1} to {chunk_end}\")\n",
    "\n",
    "                        # Extract transactions from this chunk using Camelot\n",
    "                        chunk_transactions = self.extract_statement_details(pdf_path, chunk_start + 1, chunk_end)\n",
    "                        print(f\"TDB Old chunk {chunk_start + 1}-{chunk_end}: found {len(chunk_transactions)} transactions\")\n",
    "\n",
    "                        # Save transactions from this chunk\n",
    "                        if chunk_transactions:\n",
    "                            # if self.save_transactions(chunk_transactions, account):\n",
    "                            total_transactions += len(chunk_transactions)\n",
    "                            print(f\"TDB Old chunk {chunk_start + 1}-{chunk_end}: successfully saved {len(chunk_transactions)} transactions\")\n",
    "                            # else:\n",
    "                            #     print(f\"TDB Old chunk {chunk_start + 1}-{chunk_end}: failed to save transactions\")\n",
    "\n",
    "                        # Clear chunk data from memory\n",
    "                        del chunk_transactions\n",
    "                        gc.collect()  # Force garbage collection\n",
    "\n",
    "                        chunk_start = chunk_end\n",
    "\n",
    "                    print(f\"TDB Old successfully processed {total_transactions} total transactions from pages {start_idx + 1}-{end_idx}\")\n",
    "                else:\n",
    "                    print(f\"Failed to save customer details for {pdf_path.name}\")\n",
    "\n",
    "                # result['id'] = str(customer.id)\n",
    "                result['name'] = customer['last_name'] + \" \" + customer['first_name']\n",
    "                result['account'] = account['account_number']\n",
    "                result['created_transactions'] = total_transactions\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error parsing {pdf_path}: {str(e)}\")\n",
    "\n",
    "        return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "11d74c11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully saved customer details for account 5005719683\n",
      "TDB Old processing pages 1 to 15 of 15 total pages in chunks of 10\n",
      "TDB Old processing chunk: pages 1 to 10\n",
      "TDB Old processing pages: 1,2,3,4,5,6,7,8,9,10\n",
      "Found 10 tables\n",
      "Extracted clean data count:  701\n",
      "TDB Old chunk 1-10: found 258 transactions\n",
      "TDB Old chunk 1-10: successfully saved 258 transactions\n",
      "TDB Old processing chunk: pages 11 to 15\n",
      "TDB Old processing pages: 11,12,13,14,15\n",
      "Found 5 tables\n",
      "Extracted clean data count:  321\n",
      "TDB Old chunk 11-15: found 110 transactions\n",
      "TDB Old chunk 11-15: successfully saved 110 transactions\n",
      "TDB Old successfully processed 368 total transactions from pages 1-15\n"
     ]
    }
   ],
   "source": [
    "file = \"пос хуулга.pdf\"\n",
    "\n",
    "parser_class = XacBank25Parser()\n",
    "\n",
    "result = parser_class.parse_pdf(file, 'УО02303134')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "innoscore-backend-ZFMujHlo-py3.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
