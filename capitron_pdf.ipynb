{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "2c863ddf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:222: SyntaxWarning: invalid escape sequence '\\P'\n",
      "<>:222: SyntaxWarning: invalid escape sequence '\\P'\n",
      "C:\\Users\\tnyam\\AppData\\Local\\Temp\\ipykernel_19464\\3746501387.py:222: SyntaxWarning: invalid escape sequence '\\P'\n",
      "  pdf_path = \"D:\\Projects\\pdf-statement-parser\\huulga_pdfs\\capitron2025Aug\\statement-2025-08-24 12_27_40.pdf\"\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import gc\n",
    "import logging\n",
    "import tempfile\n",
    "import pdfplumber\n",
    "import camelot\n",
    "import PyPDF2\n",
    "import pandas as pd\n",
    "from tabulate import tabulate\n",
    "from django.utils import timezone\n",
    "from sqlite3 import Row\n",
    "from pathlib import Path\n",
    "from typing import Dict, Any, Optional, Type, List\n",
    "from collections import defaultdict\n",
    "# from ..tasks.parser import write_transactions\n",
    "\n",
    "\n",
    "class CapitronBankParser():\n",
    "    \"\"\"\n",
    "    Parser for the TDB regular statement format.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        sources_dir: str = \"sources\",\n",
    "        results_dir: str = \"results\",\n",
    "        # model_class: Optional[Type[Model]] = None,\n",
    "        name_pattern: str = r'Дансны нэр\\s*([^\\n]+)',\n",
    "        account_pattern: str = r'Дансны дугаар\\s*MN(\\d+)\\s*',\n",
    "        account_type_pattern: str = r'Эхний үлдэгдэл.*\\b([A-Z]{3})\\b',\n",
    "        table_start_pattern: str = r'Огноо',\n",
    "        table_end_pattern: str = r'Огноо Гүйлгээ хийсэн банк',\n",
    "    ):\n",
    "        # super().__init__(sources_dir, results_dir)\n",
    "        self.name_pattern = name_pattern\n",
    "        self.account_pattern = account_pattern\n",
    "        self.account_type_pattern = account_type_pattern\n",
    "        self.table_start_pattern = table_start_pattern\n",
    "        self.table_end_pattern = table_end_pattern\n",
    "        self.statement_parser = 'capitronbank'\n",
    "\n",
    "    def write_transactions(self, df, settings, account):\n",
    "        # Create a list of transactions to be bulk created\n",
    "        transactions = []\n",
    "        for _, row in df.iterrows():\n",
    "            transaction_data = {\n",
    "                'account': account,\n",
    "            }\n",
    "            for field, column_name in settings['columns'].items():\n",
    "                try:\n",
    "                    if field == 'date':\n",
    "                        value = ''\n",
    "                        if isinstance(column_name, dict):\n",
    "                            for _, col in column_name.items():\n",
    "                                value += \" \" + row[col]\n",
    "                        else:\n",
    "                            value = row[column_name]\n",
    "                        if isinstance(value, str):\n",
    "                            value = value.replace(\" : \", \" \")\n",
    "                        naive_datetime = pd.to_datetime(value, errors='coerce')\n",
    "                        # transaction_data[field] = timezone.make_aware(naive_datetime) if naive_datetime is not pd.NaT else None\n",
    "                    elif field in ['income', 'expense', 'balance_end']:\n",
    "                        value = row[column_name]\n",
    "                        if pd.isna(value):\n",
    "                            transaction_data[field] = None\n",
    "                        elif value == \"-\":\n",
    "                            transaction_data[field] = None\n",
    "                        else:\n",
    "                            if isinstance(value, str):\n",
    "                                chars_to_replace = [',', '\\n']\n",
    "                                for char in chars_to_replace:\n",
    "                                    value = value.replace(char, '')\n",
    "                            value = 0 if value == \"\" else float(value)\n",
    "                            if field == 'expense':\n",
    "                                value = -abs(value)\n",
    "                            transaction_data[field] = value\n",
    "                    else:\n",
    "                        transaction_data[field] = row[column_name]\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(\"why------>\", e)\n",
    "\n",
    "            # Check if date is not null and at least one of income or expense has a value\n",
    "            # if transaction_data.get('date') not in [None, \"\"] and (transaction_data.get('income') or transaction_data.get('expense')):\n",
    "            transactions.append(transaction_data)\n",
    "\n",
    "        # print(tabulate([t.__dict__ for t in transactions], headers=\"keys\", tablefmt=\"grid\"), flush=True)\n",
    "\n",
    "        # Bulk create transactions\n",
    "        # initial_rows_number = Transaction.objects.count()\n",
    "        # Transaction.objects.bulk_create(transactions)\n",
    "\n",
    "        # return Transaction.objects.count() - initial_rows_number\n",
    "        return transactions\n",
    "\n",
    "    def extract_customer_details(self, text: str) -> Dict[str, str]:\n",
    "        \"\"\"Extract customer details from the text content.\"\"\"\n",
    "\n",
    "        details = {\n",
    "            'first_name': '',\n",
    "            'last_name': '',\n",
    "            'account_number': '',\n",
    "            'account_type': '',\n",
    "            'statement_parser': self.statement_parser\n",
    "        }\n",
    "\n",
    "        try:\n",
    "            # Extract customer name\n",
    "            name_match = re.search(self.name_pattern, text)\n",
    "            print(\"name_match: \", name_match)\n",
    "            if name_match:\n",
    "                full_name = name_match.group(1).strip()\n",
    "                # Split the name into first and last name\n",
    "                name_parts = full_name.split()\n",
    "                if len(name_parts) >= 2:\n",
    "                    details['last_name'] = name_parts[0]\n",
    "                    details['first_name'] = name_parts[1]\n",
    "\n",
    "            # Extract account number\n",
    "            account_match = re.search(self.account_pattern, text)\n",
    "            if account_match:\n",
    "                details['account_number'] = account_match.group(1)\n",
    "\n",
    "            # Extract account type\n",
    "            account_type_match = re.search(self.account_type_pattern, text)\n",
    "            if account_type_match:\n",
    "                details['account_type'] = account_type_match.group(0).strip()[-3:]\n",
    "\n",
    "            print(\"details: \", details)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error extracting customer details: {str(e)}\")\n",
    "\n",
    "        return details\n",
    "\n",
    "    def extract_statement_details(self, pdf_file: str, settings: str, account: str, start_page: int = None, end_page: int = None) -> List[Dict[str, Any]]:\n",
    "        \"\"\"\n",
    "        Extract statement details from the text content.\n",
    "\n",
    "        Args:\n",
    "            pdf_file: Either a file path string or a file object\n",
    "            start_page (int, optional): Starting page number (1-indexed). If None, starts from page 1.\n",
    "            end_page (int, optional): Ending page number (1-indexed). If None, processes all pages.\n",
    "\n",
    "        Returns:\n",
    "            List[Dict[str, Any]]: List of parsed transactions\n",
    "        \"\"\"\n",
    "\n",
    "        try:\n",
    "            # Determine page range for Camelot\n",
    "            if start_page is not None and end_page is not None:\n",
    "                # Convert to Camelot's page format (comma-separated string)\n",
    "                page_range = ','.join(str(i) for i in range(start_page, end_page + 1))\n",
    "                print(f\"Capitron pdf processing pages: {page_range}\")\n",
    "            elif start_page is not None:\n",
    "                page_range = f\"{start_page}-end\"\n",
    "                print(f\"Capitron pdf processing pages: {page_range}\")\n",
    "            elif end_page is not None:\n",
    "                page_range = f\"1-{end_page}\"\n",
    "                print(f\"Capitron pdf processing pages: {page_range}\")\n",
    "            else:\n",
    "                page_range = 'all'\n",
    "                print(\"Capitron pdf processing all pages\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error extracting tables from PDF: {str(e)}\")\n",
    "            return []\n",
    "\n",
    "        print(f\"Found {len(pdf_file.pages)} tables\")\n",
    "\n",
    "        converted_tran = []\n",
    "\n",
    "        for page_num in range(start_page - 1, end_page):\n",
    "            print(\"iterate num: \", page_num)\n",
    "            table = pdf_file.pages[page_num]\n",
    "\n",
    "            table = table.extract_tables({\n",
    "                \"vertical_strategy\": \"lines\",  # Strategy for finding columns\n",
    "                \"horizontal_strategy\": \"lines\",  # Strategy for finding rows\n",
    "            })\n",
    "\n",
    "            if table:\n",
    "                for idx, row in enumerate(table):\n",
    "                    if idx == 0:\n",
    "                        df = pd.DataFrame(row[1:], columns=row[0])\n",
    "                        headers = row[0]\n",
    "                    else:\n",
    "                        df = pd.DataFrame(row, columns=headers)\n",
    "\n",
    "                    converted_tran.append(df)\n",
    "                    print(f\"Table {idx + 1} on Page {page_num + 1}:\", flush=True)\n",
    "                    # print(tabulate(df, headers=\"keys\", tablefmt=\"grid\"), flush=True)\n",
    "            else:\n",
    "                print(f\"No tables found on Page {page_num + 1}.\", flush=True)\n",
    "\n",
    "        print(headers, flush=True)\n",
    "\n",
    "        # Concatenate all DataFrames into a single DataFrame\n",
    "        merged_df = pd.DataFrame()\n",
    "        if converted_tran:\n",
    "            merged_df = pd.concat(converted_tran, ignore_index=True)\n",
    "            print(\"Merged DataFrame:\", flush=True)\n",
    "            # print(tabulate(merged_df, headers=\"keys\", tablefmt=\"grid\"), flush=True)\n",
    "        else:\n",
    "            print(\"No tables found in the entire PDF.\", flush=True)\n",
    "\n",
    "        print(\"Columns > > > > > >\", merged_df.columns, flush=True)\n",
    "\n",
    "        try:\n",
    "            created_transactions = self.write_transactions(merged_df, settings, account)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(\"whyyy\", e)\n",
    "\n",
    "\n",
    "        return created_transactions\n",
    "\n",
    "    def parse_pdf(self, pdf_path: Path, register_number: str, request=None, start_page: int = None, end_page: int = None, chunk_size: int = 10) -> str:\n",
    "        \"\"\"Parse a single PDF file and extract its text content.\"\"\"\n",
    "\n",
    "        pdf_path = \"D:\\Projects\\pdf-statement-parser\\huulga_pdfs\\capitron2025Aug\\statement-2025-08-24 12_27_40.pdf\"\n",
    "\n",
    "        result = {\n",
    "            'id': \"\",\n",
    "            'name': \"\", # full name\n",
    "            'account': \"\",\n",
    "            'created_transactions': 0\n",
    "        }\n",
    "\n",
    "        try:\n",
    "            with pdfplumber.open(pdf_path) as pdf:\n",
    "                # Get first page for customer details\n",
    "                first_page = pdf.pages[0]\n",
    "                first_page_text = first_page.extract_text()\n",
    "\n",
    "                # Extract and save customer details\n",
    "                customer_details = self.extract_customer_details(first_page_text)\n",
    "                # customer, account = self.save_customer_details(customer_details, register_number, request)\n",
    "                account = customer_details['account_number']\n",
    "                customer = customer_details\n",
    "\n",
    "\n",
    "                if account:\n",
    "                    print(f\"Successfully saved customer details for account {account}\")\n",
    "                    # settings = BankStatementSettings.objects.get(bank=bank, type=\"pdf\")\n",
    "\n",
    "                    settings = {\n",
    "                        \"columns\": {\n",
    "                            \"date\": \"Огноо\",\n",
    "                            \"income\": \"Орлого\",\n",
    "                            \"expense\": \"Зарлага\",\n",
    "                            \"balance_end\": \"Үлдэгдэл\",\n",
    "                            \"description\": \"Гүйлгээний утга\",\n",
    "                            \"related_account\": \"Харьцсан данс / Нэр\"\n",
    "                        }\n",
    "                    }\n",
    "\n",
    "                    # Determine page range for processing\n",
    "                    total_pages = len(pdf.pages)\n",
    "                    start_idx = (start_page - 1) if start_page is not None else 0\n",
    "                    end_idx = end_page if end_page is not None else total_pages\n",
    "\n",
    "                    # Validate page range\n",
    "                    start_idx = max(0, start_idx)  # Ensure start is not negative\n",
    "                    end_idx = min(total_pages, end_idx)  # Ensure end doesn't exceed total pages\n",
    "\n",
    "                    if start_idx >= end_idx:\n",
    "                        print(f\"Invalid page range: start_page={start_page}, end_page={end_page}, total_pages={total_pages}\")\n",
    "                        return result\n",
    "\n",
    "                    print(f\"Capitron pdf processing pages {start_idx + 1} to {end_idx} of {total_pages} total pages in chunks of {chunk_size}\")\n",
    "\n",
    "                    # Process pages in chunks to prevent memory issues\n",
    "                    total_transactions = 0\n",
    "                    chunk_start = start_idx\n",
    "\n",
    "                    while chunk_start < end_idx:\n",
    "                        chunk_end = min(chunk_start + chunk_size, end_idx)\n",
    "                        print(f\"Capitron pdf processing chunk: pages {chunk_start + 1} to {chunk_end}\")\n",
    "\n",
    "                        # Extract transactions from this chunk using Camelot\n",
    "                        chunk_transactions = self.extract_statement_details(pdf, settings, account, chunk_start + 1, chunk_end)\n",
    "                        print(f\"Capitron pdf chunk {chunk_start + 1}-{chunk_end}: found {len(chunk_transactions)} transactions\")\n",
    "\n",
    "                        # Save transactions from this chunk\n",
    "                        if chunk_transactions:\n",
    "                            # if self.save_transactions(chunk_transactions, account):\n",
    "                            total_transactions += len(chunk_transactions)\n",
    "                            print(f\"Capitron pdf chunk {chunk_start + 1}-{chunk_end}: successfully saved {len(chunk_transactions)} transactions\")\n",
    "                            # else:\n",
    "                            #     print(f\"Capitron pdf chunk {chunk_start + 1}-{chunk_end}: failed to save transactions\")\n",
    "\n",
    "                        # Clear chunk data from memory\n",
    "                        del chunk_transactions\n",
    "                        gc.collect()  # Force garbage collection\n",
    "\n",
    "                        chunk_start = chunk_end\n",
    "\n",
    "                    print(f\"Capitron pdf successfully processed {total_transactions} total transactions from pages {start_idx + 1}-{end_idx}\")\n",
    "                else:\n",
    "                    print(f\"Failed to save customer details for {pdf_path.name}\")\n",
    "\n",
    "                # result['id'] = str(customer['id'])\n",
    "                result['name'] = customer['last_name'] + \" \" + customer['first_name']\n",
    "                result['account'] = account['account_number']\n",
    "                result['created_transactions'] = total_transactions\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error parsing {pdf_path}: {str(e)}\")\n",
    "\n",
    "        return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "75adefe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name_match:  <re.Match object; span=(88, 136), match='Дансны нэр ЭНХСАРУУЛ ДАВААЦЭРЭН Огноо 2025-08-24'>\n",
      "details:  {'first_name': 'ДАВААЦЭРЭН', 'last_name': 'ЭНХСАРУУЛ', 'account_number': '580030003019055588', 'account_type': 'MNT', 'statement_parser': 'capitronbank'}\n",
      "Successfully saved customer details for account 580030003019055588\n",
      "Capitron pdf processing pages 1 to 30 of 30 total pages in chunks of 10\n",
      "Capitron pdf processing chunk: pages 1 to 10\n",
      "Capitron pdf processing pages: 1,2,3,4,5,6,7,8,9,10\n",
      "Found 30 tables\n",
      "iterate num:  0\n",
      "Table 1 on Page 1:\n",
      "iterate num:  1\n",
      "Table 1 on Page 2:\n",
      "iterate num:  2\n",
      "Table 1 on Page 3:\n",
      "iterate num:  3\n",
      "Table 1 on Page 4:\n",
      "iterate num:  4\n",
      "Table 1 on Page 5:\n",
      "iterate num:  5\n",
      "Table 1 on Page 6:\n",
      "iterate num:  6\n",
      "Table 1 on Page 7:\n",
      "iterate num:  7\n",
      "Table 1 on Page 8:\n",
      "iterate num:  8\n",
      "Table 1 on Page 9:\n",
      "iterate num:  9\n",
      "Table 1 on Page 10:\n",
      "['Огноо', 'Зарлага', 'Орлого', 'Ханш', 'Харьцсан данс / Нэр', 'Үлдэгдэл', 'Гүйлгээний утга']\n",
      "Merged DataFrame:\n",
      "Columns > > > > > > Index(['Огноо', 'Зарлага', 'Орлого', 'Ханш', 'Харьцсан данс / Нэр', 'Үлдэгдэл',\n",
      "       'Гүйлгээний утга'],\n",
      "      dtype='object')\n",
      "Capitron pdf chunk 1-10: found 246 transactions\n",
      "Capitron pdf chunk 1-10: successfully saved 246 transactions\n",
      "Capitron pdf processing chunk: pages 11 to 20\n",
      "Capitron pdf processing pages: 11,12,13,14,15,16,17,18,19,20\n",
      "Found 30 tables\n",
      "iterate num:  10\n",
      "Table 1 on Page 11:\n",
      "iterate num:  11\n",
      "Table 1 on Page 12:\n",
      "iterate num:  12\n",
      "Table 1 on Page 13:\n",
      "iterate num:  13\n",
      "Table 1 on Page 14:\n",
      "iterate num:  14\n",
      "Table 1 on Page 15:\n",
      "iterate num:  15\n",
      "Table 1 on Page 16:\n",
      "iterate num:  16\n",
      "Table 1 on Page 17:\n",
      "iterate num:  17\n",
      "Table 1 on Page 18:\n",
      "iterate num:  18\n",
      "Table 1 on Page 19:\n",
      "iterate num:  19\n",
      "Table 1 on Page 20:\n",
      "['Огноо', 'Зарлага', 'Орлого', 'Ханш', 'Харьцсан данс / Нэр', 'Үлдэгдэл', 'Гүйлгээний утга']\n",
      "Merged DataFrame:\n",
      "Columns > > > > > > Index(['Огноо', 'Зарлага', 'Орлого', 'Ханш', 'Харьцсан данс / Нэр', 'Үлдэгдэл',\n",
      "       'Гүйлгээний утга'],\n",
      "      dtype='object')\n",
      "Capitron pdf chunk 11-20: found 250 transactions\n",
      "Capitron pdf chunk 11-20: successfully saved 250 transactions\n",
      "Capitron pdf processing chunk: pages 21 to 30\n",
      "Capitron pdf processing pages: 21,22,23,24,25,26,27,28,29,30\n",
      "Found 30 tables\n",
      "iterate num:  20\n",
      "Table 1 on Page 21:\n",
      "iterate num:  21\n",
      "Table 1 on Page 22:\n",
      "iterate num:  22\n",
      "Table 1 on Page 23:\n",
      "iterate num:  23\n",
      "Table 1 on Page 24:\n",
      "iterate num:  24\n",
      "Table 1 on Page 25:\n",
      "iterate num:  25\n",
      "Table 1 on Page 26:\n",
      "iterate num:  26\n",
      "Table 1 on Page 27:\n",
      "iterate num:  27\n",
      "Table 1 on Page 28:\n",
      "iterate num:  28\n",
      "Table 1 on Page 29:\n",
      "iterate num:  29\n",
      "Table 1 on Page 30:\n",
      "['Огноо', 'Зарлага', 'Орлого', 'Ханш', 'Харьцсан данс / Нэр', 'Үлдэгдэл', 'Гүйлгээний утга']\n",
      "Merged DataFrame:\n",
      "Columns > > > > > > Index(['Огноо', 'Зарлага', 'Орлого', 'Ханш', 'Харьцсан данс / Нэр', 'Үлдэгдэл',\n",
      "       'Гүйлгээний утга'],\n",
      "      dtype='object')\n",
      "Capitron pdf chunk 21-30: found 247 transactions\n",
      "Capitron pdf chunk 21-30: successfully saved 247 transactions\n",
      "Capitron pdf successfully processed 743 total transactions from pages 1-30"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error parsing D:\\Projects\\pdf-statement-parser\\huulga_pdfs\\capitron2025Aug\\statement-2025-08-24 12_27_40.pdf: string indices must be integers, not 'str'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'id': '',\n",
       " 'name': 'ЭНХСАРУУЛ ДАВААЦЭРЭН',\n",
       " 'account': '',\n",
       " 'created_transactions': 0}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser = CapitronBankParser()\n",
    "parser.parse_pdf(\"D:\\\\Projects\\\\pdf-statement-parser\\\\huulga_pdfs\\\\05-khasbank.pdf\", \"УО02303134\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "innoscore-backend-ZFMujHlo-py3.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
